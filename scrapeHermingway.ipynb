{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPwPIXpI03plrTmmEQ4kzqP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjiahao/business-analytics/blob/master/scrapeHermingway.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M65W75TmU5v8",
        "colab_type": "text"
      },
      "source": [
        "The Sun Also Rises (1926) http://gutenberg.ca/ebooks/hemingwaye-sunalsorises/hemingwaye-sunalsorises-00-h.html\n",
        "\n",
        "Men Without Women (1927) http://gutenberg.ca/ebooks/hemingwaye-menwithoutwomen/hemingwaye-menwithoutwomen-00-h.html\n",
        "\n",
        "Winner Take Nothing (1933) http://gutenberg.ca/ebooks/hemingwaye-winnertakenothing/hemingwaye-winnertakenothing-00-h.html\n",
        "\n",
        "Green Hills of Africa (1935) http://gutenberg.ca/ebooks/hemingwaye-greenhillsofafrica/hemingwaye-greenhillsofafrica-00-h.html\n",
        "\n",
        "Across the River and Into the Trees (1950) http://gutenberg.ca/ebooks/hemingwaye-acrosstheriver/hemingwaye-acrosstheriver-00-h.html\n",
        "\n",
        "The Old Man and the Sea (1952) http://gutenberg.ca/ebooks/hemingwaye-oldmanandthesea/hemingwaye-oldmanandthesea-00-h.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJrJIXboU4Ee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Web Scraping\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Preprocess\n",
        "import spacy\n",
        "import string\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "nltk.download('punkt')\n",
        "stop_words = set(stopwords.words('english')) \n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# EDA\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
        "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import homogeneity_score\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Viz\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoXNMFOeVDeW",
        "colab_type": "text"
      },
      "source": [
        "## Web Scraping using BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6Qc8XbYVATm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'http://gutenberg.ca/ebooks/hemingwaye-sunalsorises/hemingwaye-sunalsorises-00-h.html'\n",
        "res = requests.get(url)\n",
        "html_page = res.content\n",
        "\n",
        "soup = BeautifulSoup(html_page, 'html.parser')\n",
        "\n",
        "text = soup.find_all(text=True)\n",
        "\n",
        "set([t.parent.name for t in text])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nfm8O1d8VKJG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "output = ''\n",
        "for t in text:\n",
        "    if t.parent.name in ['p']:\n",
        "        output += '{} '.format(t)\n",
        "#output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCF0_3-HVM11",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Web_Scraping(url):\n",
        "    res = requests.get(url)\n",
        "    html_page = res.content\n",
        "    soup = BeautifulSoup(html_page, 'html.parser')\n",
        "    text = soup.find_all(text=True)\n",
        "    output = ''\n",
        "    for t in text:\n",
        "        if t.parent.name in ['p']:\n",
        "            output += '{} '.format(t)\n",
        "    output = output.strip().replace(\"\\n\", \" \").replace(\"\\r\", \" \").replace(\"\\r\\n\", \" \").replace(\"  \", \" \")\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZeuqwkaVOyl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url_1 = \"http://gutenberg.ca/ebooks/hemingwaye-sunalsorises/hemingwaye-sunalsorises-00-h.html\"\n",
        "book_1 = Web_Scraping(url_1)\n",
        "url_2 = \"http://gutenberg.ca/ebooks/hemingwaye-menwithoutwomen/hemingwaye-menwithoutwomen-00-h.html\"\n",
        "book_2 = Web_Scraping(url_2)\n",
        "url_3 = \"http://gutenberg.ca/ebooks/hemingwaye-winnertakenothing/hemingwaye-winnertakenothing-00-h.html\"\n",
        "book_3 = Web_Scraping(url_3)\n",
        "url_4 = \"http://gutenberg.ca/ebooks/hemingwaye-greenhillsofafrica/hemingwaye-greenhillsofafrica-00-h.html\"\n",
        "book_4 = Web_Scraping(url_4)\n",
        "url_5 = \"http://gutenberg.ca/ebooks/hemingwaye-acrosstheriver/hemingwaye-acrosstheriver-00-h.html\"\n",
        "book_5 = Web_Scraping(url_5)\n",
        "url_6 = \"http://gutenberg.ca/ebooks/hemingwaye-oldmanandthesea/hemingwaye-oldmanandthesea-00-h.html\"\n",
        "book_6 = Web_Scraping(url_6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsUT5fH6VH_6",
        "colab_type": "text"
      },
      "source": [
        "## Text Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3RDBzZhVUHY",
        "colab_type": "text"
      },
      "source": [
        "## Ideas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVym0ZEFVXOn",
        "colab_type": "text"
      },
      "source": [
        "# Number of distinct words (vocabulary)\n",
        "# Lexical diversity = vocabulary/token ratio\n",
        "# Distribution of word lengths\n",
        "# Most frequent words\n",
        "# Number of n-gram word (bigrams, trigrams, 4-grams, etc.)\n",
        "# Usage of passive and active voice\n",
        "# Usage of parts of speech (nouns, verb, adverbs, adjectives, etc.)\n",
        "# Sentiment (positive, negative)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ui31NVN8VaUB",
        "colab_type": "text"
      },
      "source": [
        "###  Book Level"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbTcT4K7VrpS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_books = {'book': ['book_1','book_2','book_3','book_4','book_5', 'book_6'],\n",
        "             'text': [book_1, book_2, book_3, book_4, book_5, book_6]}\n",
        "\n",
        "all_books = pd.DataFrame(all_books, columns = ['book', 'text'])\n",
        "all_books"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0oIRSAeVw6l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Counting Vocabulary\n",
        "all_books['token'] = all_books['text'].apply(word_tokenize)\\\n",
        ".apply(lambda x: [item for item in x if item.isalpha()])\n",
        "\n",
        "all_books['token count'] = all_books['token'].apply(len)\n",
        "all_books['vocab count'] = all_books['token'].apply(set).apply(len)\n",
        "all_books['lexical_diversity'] = all_books['vocab count']/all_books['token count']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyTSDGygVzsq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sid = SentimentIntensityAnalyzer()\n",
        "all_books['scores sentiment'] = all_books['text'].apply(lambda x: sid.polarity_scores(x))\n",
        "all_books"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFYGylsrVu57",
        "colab_type": "text"
      },
      "source": [
        "## Sentence Level"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXb8lgyEV5FA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_sents(book):\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    doc = nlp(book)\n",
        "    sent_list = []\n",
        "    for sent in doc.sents:\n",
        "        sent_list.append(sent.text)\n",
        "    return sent_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IRwwGuwV8Yt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sents_1 = get_sents(book_1)\n",
        "df_1 = {'sentence': sents_1,\n",
        "        'book': 'Book_1'}\n",
        "df_1 = pd.DataFrame(df_1, columns = ['sentence', 'book'])\n",
        "len(sents_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPJML_foV-Pz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sents_2 = get_sents(book_2)\n",
        "df_2 = {'sentence': sents_2,\n",
        "        'book': 'Book_2'}\n",
        "df_2 = pd.DataFrame(df_2, columns = ['sentence', 'book'])\n",
        "len(sents_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaFBFZg2WA0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sents_2 = get_sents(book_2)\n",
        "df_2 = {'sentence': sents_2,\n",
        "        'book': 'Book_2'}\n",
        "df_2 = pd.DataFrame(df_2, columns = ['sentence', 'book'])\n",
        "len(sents_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ln0cjPsWCl6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sents_4 = get_sents(book_4)\n",
        "df_4 = {'sentence': sents_4,\n",
        "        'book': 'Book_4'}\n",
        "df_4 = pd.DataFrame(df_4, columns = ['sentence', 'book'])\n",
        "len(sents_4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjrRa25OWEsA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sents_5 = get_sents(book_5)\n",
        "df_5 = {'sentence': sents_5,\n",
        "        'book': 'Book_5'}\n",
        "df_5 = pd.DataFrame(df_5, columns = ['sentence', 'book'])\n",
        "len(sents_5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x-FoCLTWGwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sents_6 = get_sents(book_6)\n",
        "df_6 = {'sentence': sents_6,\n",
        "        'book': 'Book_6'}\n",
        "df_6 = pd.DataFrame(df_6, columns = ['sentence', 'book'])\n",
        "len(sents_6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKorwLrDWI3K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_all = pd.concat([df_1, df_2, df_3, df_4, df_5, df_6]).reset_index(drop=True)\n",
        "df_all.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91tQdSEMWLvz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(sents_1)+len(sents_2)+len(sents_3)+len(sents_4)+len(sents_5)+len(sents_6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpvEYFRvWWb4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_all['token'] = df_all['sentence'].apply(word_tokenize)\\\n",
        ".apply(lambda x: [item for item in x if item.isalpha()])\n",
        "\n",
        "# after remove stopwords and stemmer\n",
        "stop = stopwords.words('english')\n",
        "porter_stemmer = PorterStemmer()\n",
        "df_all['clean token'] = df_all['token'].apply(lambda x: [item for item in x if item not in stop_words])\\\n",
        ".apply(lambda x: [porter_stemmer.stem(item) for item in x])\n",
        "df_all.head(15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7pT7A2lWYg7",
        "colab_type": "text"
      },
      "source": [
        "##  Advanced Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-r6zlcfRWaIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The default regexp select tokens of 2 or more alphanumeric characters \n",
        "# And punctuation is completely ignored and always treated as a token separator\n",
        "# Use unigrams \n",
        "count_vect = CountVectorizer(stop_words='english')\n",
        "X_counts = count_vect.fit_transform(df_all.sentence)\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X_tfidf = tfidf_transformer.fit_transform(X_counts)\n",
        "print(X_tfidf.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRY82kx6WcuC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for reproducibility\n",
        "random_state = 666\n",
        "cls = MiniBatchKMeans(n_clusters=6, random_state=random_state)\n",
        "cls.fit(X_tfidf)\n",
        "cls.predict(X_tfidf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GMNqfXsWgDq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reduce the features to 2D\n",
        "pca = PCA(n_components=2, random_state=random_state)\n",
        "reduced_features = pca.fit_transform(X_tfidf.toarray())\n",
        "\n",
        "# reduce the cluster centers to 2D\n",
        "reduced_cluster_centers = pca.transform(cls.cluster_centers_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK2Vc33oWh7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.scatter(reduced_features[:,0], reduced_features[:,1], c=cls.predict(X_tfidf))\n",
        "plt.scatter(reduced_cluster_centers[:, 0], reduced_cluster_centers[:,1], marker='x', s=150, c='b')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJjgUmuNWkqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reduced_cluster_centers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebeYPpSnWnTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evalauation with labelled dataset\n",
        "homogeneity_score(df_all.book, cls.predict(X_tfidf))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tj872u_EWpP-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The best value is 1 and the worst value is -1. \n",
        "# Values near 0 indicate overlapping clusters. \n",
        "silhouette_score(X_tfidf, labels=cls.predict(X_tfidf))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvOSeXjTWrvI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The best value is 1 and the worst value is -1. \n",
        "# Values near 0 indicate overlapping clusters. \n",
        "silhouette_score(X_tfidf, labels=cls.predict(X_tfidf))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_ut95gzWuk5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#add the cluster label to the data frame\n",
        "df_all['cluster'] = kmeans.labels_\n",
        "clusters = df_all.groupby(['cluster', 'book']).size()\n",
        "fig, ax1 = plt.subplots(figsize = (26, 15))\n",
        "sns.heatmap(clusters.unstack(level = 'book'), ax = ax1, cmap = 'Reds')\n",
        "ax1.set_xlabel('book').set_size(18)\n",
        "ax1.set_ylabel('cluster').set_size(18)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}